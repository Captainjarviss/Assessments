# -*- coding: utf-8 -*-
"""LVADSUSR71-Arpit-FA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10eEp2TdQ1RveSuj3pgBfYH33yaarN-9p
"""

import pandas as pd
df=pd.read_csv('/content/Walmart_Dataset Python_Final_Assessment.csv')

#q1
import pandas as pd

print("Number of rows:", df.shape[0])
print("Number of columns:", df.shape[1])

print("\nData types:")
print(df.dtypes)

print("\nSummarry statistics for numerical columns:")
print(df.describe())

print("\nThree quartiles for numerical columns:")
print(df.quantile([0.25, 0.5, 0.75]))

print("\nMissing values:")
print(df.isnull().sum())

#q2
import pandas as pd


missing_values = df.isnull().sum()


threshold = len(df) * 0.2
columns_to_drop = missing_values[missing_values > threshold].index
df.drop(columns=columns_to_drop, inplace=True)


df.fillna(df.mean(), inplace=True)

df.drop_duplicates(inplace=True)
print(df.drop_duplicates)

#q3
import pandas as pd

mean_values = df.mean()


median_values = df.median()

mode_values = df.mode().iloc[0]

variance_values = df.var()

std_deviation_values = df.std()

print("Mean:")
print(mean_values)
print("\nMedian:")
print(median_values)
print("\nMode:")
print(mode_values)
print("\nVariance:")
print(variance_values)
print("\nStandard Deviation:")
print(std_deviation_values)

#q4
import pandas as pd
import matplotlib.pyplot as plt

df['Quantity'].hist()
plt.title('Quantity Distribution')
plt.xlabel('Made')
plt.ylabel('Frequency')
plt.show()


plt.scatter(df['Profit'], df['Sales'])
plt.title('Weekly Sales vs. Profit')
plt.xlabel('Profit')
plt.ylabel('Sales')
plt.show()



dept_sales = df.groupby('Category')['Sales'].sum()
dept_sales.plot(kind='pie', figsize=(10, 6))
plt.title('Total Weekly Sales by Department')
plt.xlabel('Department')
plt.ylabel(' ')
plt.show()

#q5
correlation_matrix = df.corr()
print(correlation_matrix)
correlation_matrix.hist()
plt.title('Correlation')
plt.xlabel('x ')
plt.ylabel('y')
plt.show()

#q6
import pandas as pd
df = pd.read_csv('/content/Walmart_Dataset Python_Final_Assessment.csv')

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

outliers = df[((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

print(outliers)

#q7
#Trend Analysis
import pandas as pd
df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Year'] = df['Order Date'].dt.year
sales_profit_trends = df.groupby('Year').agg({'Sales': 'sum', 'Profit': 'sum'})
sales_profit_trends.plot(kind='line', subplots=True)

sales_by_category = df.groupby(['Year', 'Category']).agg({'Sales': 'sum'}).unstack()
sales_by_category.plot(kind='line', marker='o', figsize=(10, 6))

#q7
#Customer Analysis
import pandas as pd


top_customers_orders = df.groupby('EmailID')['Order ID'].nunique().nlargest(5)
top_customers_sales = df.groupby('EmailID')['Sales'].sum().nlargest(5)
print('Top_customer_order: ',top_customers_orders)
print('Top_Cusotmers_Sales: ',top_customers_sales)

df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Order Date Previous'] = df.groupby('EmailID')['Order Date'].shift(1)
df['Time Between Orders'] = df['Order Date'] - df['Order Date Previous']
average_time_between_orders = df.groupby('EmailID')['Time Between Orders'].mean()

#q7
#Comprehensive Analytics
import pandas as pd

high_value_customers = df[df['Quantity'] > df['Quantity'].quantile(0.75)]
print(high_value_customers)
